package manager

import (
	"context"
	"fmt"
	"strings"
	"time"

	v1 "k8s.io/api/core/v1"
	apierrors "k8s.io/apimachinery/pkg/api/errors"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	utilerrors "k8s.io/apimachinery/pkg/util/errors"
	"k8s.io/apimachinery/pkg/util/sets"
	"k8s.io/klog"
	"sigs.k8s.io/controller-runtime/pkg/client"
	"sigs.k8s.io/prow/pkg/metrics"

	"github.com/ghodss/yaml"
	"github.com/openshift/ci-chat-bot/pkg/utils"
	hivev1 "github.com/openshift/hive/apis/hive/v1"
	"github.com/openshift/installer/pkg/ipnet"
	installer "github.com/openshift/installer/pkg/types"
	"github.com/openshift/installer/pkg/types/aws"
	"github.com/openshift/installer/pkg/types/gcp"
	clusterv1 "open-cluster-management.io/api/cluster/v1"

	hiveaws "github.com/openshift/hive/apis/hive/v1/aws"
	hivegcp "github.com/openshift/hive/apis/hive/v1/gcp"
)

var MCEPlatforms = sets.New([]string{"aws", "gcp"}...)

func (m *jobManager) createManagedCluster(imageSet, platform, user, slackChannel string, req *JobRequest, duration time.Duration) (*clusterv1.ManagedCluster, error) {
	m.mceConfig.Mutex.RLock()
	mceUserConfig := m.mceConfig.Users[user]
	m.mceConfig.Mutex.RUnlock()
	clusterName, err := generateRandomString(12, true)
	if err != nil {
		// this case should never happen
		return nil, fmt.Errorf("failed to generate random name: %v", err)
	}
	clusterName = fmt.Sprintf("chat-bot-%s", clusterName)

	// try to create prowjob early so we can fail before creation of resources
	if req != nil {
		req.ManagedClusterName = clusterName
		// the LaunchJobForUser function returns an error on successful creation of build jobs, so we need an extra check on the error text...
		if _, err := m.LaunchJobForUser(req); err != nil && !strings.Contains(err.Error(), "you will be notified on completion") {
			metrics.RecordError(errorMCELaunchImagesetJob, m.errorMetric)
			return nil, fmt.Errorf("failed to create job to generate requested image: %w", err)
		}
	}

	// All managed clusters get their own namespace. The namespace is automatically deleted when the ManagedCluster within it is deleted.
	if _, err := m.dpcrNamespaceClient.Create(context.TODO(), &v1.Namespace{ObjectMeta: metav1.ObjectMeta{Name: clusterName, Labels: map[string]string{utils.LaunchLabel: "true"}}}, metav1.CreateOptions{}); err != nil {
		metrics.RecordError(errorMCECreateNamespace, m.errorMetric)
		return nil, fmt.Errorf("failed to create namespace: %w", err)
	}

	// copy credentials from main chat-bot secrets namespace
	chatBotSecretsClient := m.dpcrCoreClient.Secrets("crt-argocd")
	clusterSecretsClient := m.dpcrCoreClient.Secrets(clusterName)
	credentialsName := fmt.Sprintf("%s-credentials", platform)
	if platform == "aws" && mceUserConfig.AwsSecret != "" {
		credentialsName = m.mceConfig.Users[user].AwsSecret
	} else if platform == "gcp" && mceUserConfig.GcpSecret != "" {
		credentialsName = m.mceConfig.Users[user].GcpSecret
	}
	platformCreds, err := chatBotSecretsClient.Get(context.TODO(), credentialsName, metav1.GetOptions{})
	if err != nil {
		metrics.RecordError(errorMCEGetPlatformCredentials, m.errorMetric)
		return nil, fmt.Errorf("failed to get platform (%s) credentials: %v", platform, err)
	}
	// reset metadata
	platformCreds.ObjectMeta = metav1.ObjectMeta{}
	platformCreds.TypeMeta = metav1.TypeMeta{}
	platformCreds.SetNamespace(clusterName)
	platformCreds.SetName(fmt.Sprintf("%s-%s-creds", clusterName, platform))
	if _, err := clusterSecretsClient.Create(context.TODO(), platformCreds, metav1.CreateOptions{}); err != nil {
		metrics.RecordError(errorMCECreatePlatformCredentials, m.errorMetric)
		return nil, fmt.Errorf("failed to create platform (%s) credentials: %v", platform, err)
	}
	pullSecret, err := chatBotSecretsClient.Get(context.TODO(), "mce-pull-secret", metav1.GetOptions{})
	if err != nil {
		metrics.RecordError(errorMCEGetPullSecret, m.errorMetric)
		return nil, fmt.Errorf("failed to get pull secret: %v", err)
	}
	// reset metadata
	pullSecret.ObjectMeta = metav1.ObjectMeta{}
	pullSecret.TypeMeta = metav1.TypeMeta{}
	pullSecret.SetNamespace(clusterName)
	pullSecret.SetName(fmt.Sprintf("%s-pull-secret", clusterName))
	if _, err := clusterSecretsClient.Create(context.TODO(), pullSecret, metav1.CreateOptions{}); err != nil {
		metrics.RecordError(errorMCECreatePullSecret, m.errorMetric)
		return nil, fmt.Errorf("failed to create pull secret: %v", err)
	}
	var baseDomain string
	if platform == "gcp" {
		baseDomain = fmt.Sprintf("openshift-crt-mce.%s.devcluster.openshift.com", platform)
	} else {
		baseDomain = fmt.Sprintf("crt-mce-%s.devcluster.openshift.com", platform)
	}
	if platform == "aws" && mceUserConfig.AwsBaseDomain != "" {
		baseDomain = mceUserConfig.AwsBaseDomain
	} else if platform == "gcp" && mceUserConfig.GcpBaseDomain != "" {
		baseDomain = mceUserConfig.GcpBaseDomain
	}
	replicas := int64(3)
	// copied from autogenerated installConfig from web interface
	installConfig := &installer.InstallConfig{
		TypeMeta: metav1.TypeMeta{
			APIVersion: "v1",
		},
		ObjectMeta: metav1.ObjectMeta{
			Name: clusterName,
		},
		BaseDomain: baseDomain,
		ControlPlane: &installer.MachinePool{
			Hyperthreading: "Enabled",
			Name:           "master",
			Replicas:       &replicas,
		},
		Compute: []installer.MachinePool{{
			Hyperthreading: "Enabled",
			Name:           "worker",
			Replicas:       &replicas,
		}},
		Networking: &installer.Networking{
			NetworkType: "OVNKubernetes",
			ClusterNetwork: []installer.ClusterNetworkEntry{
				{
					CIDR:       *ipnet.MustParseCIDR("10.128.0.0/14"),
					HostPrefix: 23,
				},
			},
			MachineNetwork: []installer.MachineNetworkEntry{
				{
					CIDR: *ipnet.MustParseCIDR("10.0.0.0/16"),
				},
			},
			ServiceNetwork: []ipnet.IPNet{*ipnet.MustParseCIDR("172.30.0.0/16")},
		},
		PullSecret: "", // skip, hive will inject based on it's secrets
	}
	switch platform {
	case "aws":
		installConfig.ControlPlane.Platform = installer.MachinePoolPlatform{
			AWS: &aws.MachinePool{
				Zones: []string{"us-east-1a"},
				EC2RootVolume: aws.EC2RootVolume{
					IOPS: 2000,
					Size: 100,
					Type: "io1",
				},
				InstanceType: "m6a.xlarge",
			},
		}
		installConfig.Compute[0].Platform = installer.MachinePoolPlatform{
			AWS: &aws.MachinePool{
				Zones: []string{"us-east-1a"},
				EC2RootVolume: aws.EC2RootVolume{
					IOPS: 2000,
					Size: 100,
					Type: "io1",
				},
				InstanceType: "m6a.xlarge",
			},
		}
		installConfig.Platform = installer.Platform{
			AWS: &aws.Platform{
				Region: "us-east-1",
			},
		}
	case "gcp":
		installConfig.ControlPlane.Platform = installer.MachinePoolPlatform{
			GCP: &gcp.MachinePool{
				InstanceType: "n1-standard-4",
			},
		}
		installConfig.Compute[0].Platform = installer.MachinePoolPlatform{
			GCP: &gcp.MachinePool{
				InstanceType: "n1-standard-4",
			},
		}
		projectID := "openshift-crt-mce"
		if mceUserConfig.GcpProjectID != "" {
			projectID = mceUserConfig.GcpProjectID
		}
		installConfig.Platform = installer.Platform{
			GCP: &gcp.Platform{
				Region:    "us-east1",
				ProjectID: projectID,
			},
		}
	}
	installConfigBytes, err := yaml.Marshal(installConfig)
	if err != nil {
		return nil, fmt.Errorf("failed to marshal install config: %v", err)
	}
	installConfigSecret := v1.Secret{
		ObjectMeta: metav1.ObjectMeta{
			Name:      fmt.Sprintf("%s-install-config", clusterName),
			Namespace: clusterName,
		},
		Type: v1.SecretTypeOpaque,
		Data: map[string][]byte{
			"install-config.yaml": installConfigBytes,
		},
	}
	if _, err := clusterSecretsClient.Create(context.TODO(), &installConfigSecret, metav1.CreateOptions{}); err != nil {
		metrics.RecordError(errorMCECreateInstallConfig, m.errorMetric)
		return nil, fmt.Errorf("failed to create install config secret: %v", err)
	}

	expiryTime := time.Now().Add(duration).Format(time.RFC3339)
	managedCluster := clusterv1.ManagedCluster{
		ObjectMeta: metav1.ObjectMeta{
			Name: clusterName,
			Labels: map[string]string{
				"name":   clusterName,
				"vendor": "OpenShift",
				"cluster.open-cluster-management.io/clusterset": "ci-chat-bot",
				utils.LaunchLabel: "true",
			},
			Annotations: map[string]string{
				utils.UserTag:        user,
				utils.ChannelTag:     slackChannel,
				utils.ExpiryTimeTag:  expiryTime,
				utils.BaseDomain:     baseDomain,
				utils.RequestTimeTag: time.Now().Format(time.RFC3339),
			},
		},
		Spec: clusterv1.ManagedClusterSpec{
			HubAcceptsClient: true,
		},
	}
	if req != nil {
		managedCluster.Annotations[utils.CustomImageTag] = "true"
	}

	switch platform {
	case "aws":
		managedCluster.Labels["Cloud"] = "Amazon"
		managedCluster.Labels["Region"] = "us-east-1"
	case "gcp":
		managedCluster.Labels["Cloud"] = "Google"
		managedCluster.Labels["Region"] = "us-east1"
	}

	if err := m.dpcrOcmClient.Create(context.TODO(), &managedCluster, &client.CreateOptions{}); err != nil {
		metrics.RecordError(errorMCECreateManagedCluster, m.errorMetric)
		return nil, fmt.Errorf("failed to create managed cluster object: %v", err)
	}

	// if the user requested a release that exists as GA, we can start deployment immediately
	if req == nil {
		if err := m.createClusterDeployment(clusterName, imageSet, baseDomain, platform); err != nil {
			return nil, err
		}
	}

	return &managedCluster, nil
}

func (m *jobManager) createClusterDeployment(clusterName, imageset, baseDomain, platform string) error {
	attemptLimit := int32(2)
	clusterDeployment := hivev1.ClusterDeployment{
		ObjectMeta: metav1.ObjectMeta{
			Name:      clusterName,
			Namespace: clusterName,
			Labels: map[string]string{
				"vendor": "OpenShift",
				"cluster.open-cluster-management.io/clusterset": "ci-chat-bot",
			},
		},
		Spec: hivev1.ClusterDeploymentSpec{
			BaseDomain:  baseDomain,
			ClusterName: clusterName,
			ControlPlaneConfig: hivev1.ControlPlaneConfigSpec{
				ServingCertificates: hivev1.ControlPlaneServingCertificateSpec{},
			},
			InstallAttemptsLimit: &attemptLimit,
			Installed:            false,
			Provisioning: &hivev1.Provisioning{
				InstallConfigSecretRef: &v1.LocalObjectReference{
					Name: fmt.Sprintf("%s-install-config", clusterName),
				},
				ImageSetRef: &hivev1.ClusterImageSetReference{
					Name: imageset,
				},
			},
			PullSecretRef: &v1.LocalObjectReference{
				Name: fmt.Sprintf("%s-pull-secret", clusterName),
			},
		},
	}

	switch platform {
	case "aws":
		clusterDeployment.Labels["cloud"] = "AWS"
		clusterDeployment.Labels["region"] = "us-east-1"
		clusterDeployment.Spec.Platform = hivev1.Platform{
			AWS: &hiveaws.Platform{
				CredentialsSecretRef: v1.LocalObjectReference{
					Name: fmt.Sprintf("%s-%s-creds", clusterName, platform),
				},
				Region: "us-east-1",
			},
		}
	case "gcp":
		clusterDeployment.Labels["cloud"] = "GCP"
		clusterDeployment.Labels["region"] = "us-east1"
		clusterDeployment.Spec.Platform = hivev1.Platform{
			GCP: &hivegcp.Platform{
				CredentialsSecretRef: v1.LocalObjectReference{
					Name: fmt.Sprintf("%s-%s-creds", clusterName, platform),
				},
				Region: "us-east1",
			},
		}
	}

	if err := m.dpcrHiveClient.Create(context.TODO(), &clusterDeployment, &client.CreateOptions{}); err != nil {
		metrics.RecordError(errorMCECreateDeployment, m.errorMetric)
		return fmt.Errorf("failed to create cluster deployment: %v", err)
	}
	return nil
}

func (m *jobManager) listManagedClusters() ([]*clusterv1.ManagedCluster, []*hivev1.ClusterDeployment, error) {
	namespaces, err := m.dpcrNamespaceClient.List(context.TODO(), metav1.ListOptions{LabelSelector: utils.LaunchLabel})
	if err != nil {
		metrics.RecordError(errorMCEListManagedNamespaces, m.errorMetric)
		return nil, nil, fmt.Errorf("failed to get list of managed clusters: %v", err)
	}
	managedClusters := []*clusterv1.ManagedCluster{}
	clusterDeployments := []*hivev1.ClusterDeployment{}
	for _, namespace := range namespaces.Items {
		cluster := clusterv1.ManagedCluster{}
		if err := m.dpcrOcmClient.Get(context.TODO(), client.ObjectKey{Namespace: namespace.Name, Name: namespace.Name}, &cluster); err != nil {
			klog.Warningf("Failed to get managed cluster %s; cluster is likely being deleted: %v", namespace.Name, err)
		} else {
			managedClusters = append(managedClusters, &cluster)
		}
		clusterDeployment := hivev1.ClusterDeployment{}
		if err := m.dpcrHiveClient.Get(context.TODO(), client.ObjectKey{Namespace: namespace.Name, Name: namespace.Name}, &clusterDeployment); err != nil {
			klog.Warningf("Failed to get cluster deployment %s; cluster is likely being deleted or waiting for a custom image build: %v", namespace.Name, err)
		} else {
			clusterDeployments = append(clusterDeployments, &clusterDeployment)
		}
	}
	return managedClusters, clusterDeployments, nil
}

// getClusterAuth returns kubeconfig,password,error
func (m *jobManager) getClusterAuth(name string) (string, string, error) {
	m.mceClusters.lock.RLock()
	// don't pull clusterdeployment if auth is already cached
	existingKubeconfig, ok := m.mceClusters.clusterKubeconfigs[name]
	existingPassword, ok2 := m.mceClusters.clusterPasswords[name]
	m.mceClusters.lock.RUnlock()
	if ok && ok2 && existingKubeconfig != "" && existingPassword != "" {
		return existingKubeconfig, existingPassword, nil
	}
	clusterDeployment := hivev1.ClusterDeployment{}
	if err := m.dpcrHiveClient.Get(context.TODO(), client.ObjectKey{Namespace: name, Name: name}, &clusterDeployment); err != nil {
		metrics.RecordError(errorMCEGetDeployment, m.errorMetric)
		return "", "", err
	}
	if clusterDeployment.Spec.ClusterMetadata == nil {
		return "", "", nil
	}
	secretsClient := m.dpcrCoreClient.Secrets(name)
	kubeconfigSecret, err := secretsClient.Get(context.TODO(), clusterDeployment.Spec.ClusterMetadata.AdminKubeconfigSecretRef.Name, metav1.GetOptions{})
	if err != nil {
		metrics.RecordError(errorMCEGetAuthSecrets, m.errorMetric)
		return "", "", err
	}
	passwordSecret, err := secretsClient.Get(context.TODO(), clusterDeployment.Spec.ClusterMetadata.AdminPasswordSecretRef.Name, metav1.GetOptions{})
	if err != nil {
		metrics.RecordError(errorMCEGetAuthSecrets, m.errorMetric)
		return "", "", err
	}
	m.mceClusters.lock.Lock()
	defer m.mceClusters.lock.Unlock()
	if m.mceClusters.clusterKubeconfigs == nil {
		m.mceClusters.clusterKubeconfigs = make(map[string]string)
	}
	m.mceClusters.clusterKubeconfigs[name] = string(kubeconfigSecret.Data["kubeconfig"])
	if m.mceClusters.clusterPasswords == nil {
		m.mceClusters.clusterPasswords = make(map[string]string)
	}
	m.mceClusters.clusterPasswords[name] = string(passwordSecret.Data["password"])
	return string(kubeconfigSecret.Data["kubeconfig"]), string(passwordSecret.Data["password"]), nil
}

func (m *jobManager) deleteManagedCluster(cluster *clusterv1.ManagedCluster) error {
	name := cluster.Name
	errs := []error{}
	if val, ok := cluster.Annotations[utils.CustomImageTag]; ok && val == "true" {
		if err := m.dpcrHiveClient.Delete(context.TODO(), &hivev1.ClusterImageSet{ObjectMeta: metav1.ObjectMeta{Name: name, Namespace: name}}, &client.DeleteOptions{}); err != nil && !apierrors.IsNotFound(err) {
			metrics.RecordError(errorMCEDeleteClusterImageset, m.errorMetric)
			errs = append(errs, fmt.Errorf("failed to delete clusterdeployment object: %v", err))
		}
	}
	if err := m.dpcrHiveClient.Delete(context.TODO(), &hivev1.ClusterDeployment{ObjectMeta: metav1.ObjectMeta{Name: name, Namespace: name}}, &client.DeleteOptions{}); err != nil && !apierrors.IsNotFound(err) {
		metrics.RecordError(errorMCEDeleteDeployment, m.errorMetric)
		errs = append(errs, fmt.Errorf("failed to delete clusterdeployment object: %v", err))
	}
	if err := m.dpcrOcmClient.Delete(context.TODO(), &clusterv1.ManagedCluster{ObjectMeta: metav1.ObjectMeta{Name: name, Namespace: name}}, &client.DeleteOptions{}); err != nil && !apierrors.IsNotFound(err) {
		metrics.RecordError(errorMCEDeleteManagedCluster, m.errorMetric)
		errs = append(errs, fmt.Errorf("failed to delete managed cluster object: %v", err))
	}
	return utilerrors.NewAggregate(errs)
}

func (m *jobManager) createCustomImageset(releaseURL, imagesetName string) error {
	imageset := hivev1.ClusterImageSet{
		ObjectMeta: metav1.ObjectMeta{
			Name: imagesetName,
			Labels: map[string]string{
				utils.LaunchLabel: "true",
			},
		},
		Spec: hivev1.ClusterImageSetSpec{
			ReleaseImage: releaseURL,
		},
	}
	return m.dpcrHiveClient.Create(context.TODO(), &imageset)
}
